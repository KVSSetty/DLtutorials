{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catvsdog.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYwH6v0wcfdWKLspLjbVou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KVSSetty/DLtutorials/blob/master/catvsdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi--_jAaSOe7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "metadata": {
        "id": "c1Zi7dHuS4am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "w-KlFBrVTTsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq dogs-vs-cats.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "CDe9UsSDTsco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq train.zip\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DL4_0Wc992ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "  \n",
        "original_dir = pathlib.Path(\"train\")                          \n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")             \n",
        " \n",
        "def make_subset(subset_name, start_index, end_index):         \n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" \n",
        "                  for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "make_subset(\"train\", start_index=0, end_index=1000)            \n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)    \n",
        "make_subset(\"test\", start_index=1500, end_index=2500)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3hqpIlTlUxAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Let us build a CNN"
      ],
      "metadata": {
        "id": "3PRl8h093-PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "  \n",
        "inputs = keras.Input(shape=(180, 180, 3))                            \n",
        "x = layers.Rescaling(1./255)(inputs)                                 \n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "vwgkwRKlDt0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "w1LN9B2KErGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CSAK0P9OEyym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n"
      ],
      "metadata": {
        "id": "Lf4M3hnEHBid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n"
      ],
      "metadata": {
        "id": "jVt19hfhHIn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "EDMWF4mNHQRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Displaying the shapes of the data and labels yielded by the Dataset\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "i7PutV6PJR-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "     print(\"data batch shape:\", data_batch.shape)\n",
        "     print(\"labels batch shape:\", labels_batch.shape)\n",
        "     break\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VZZomRCuJfvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the model using a Dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1QsEePDPLXHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "id": "lV0MoYUgLiez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying curves of loss and accuracy during training\n",
        "\n"
      ],
      "metadata": {
        "id": "EqnCMgd4MEbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V_gYUTprL6wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model on the test set\n",
        "\n"
      ],
      "metadata": {
        "id": "vMaEgyvXNotD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset) \n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oQpt_UavMb_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}